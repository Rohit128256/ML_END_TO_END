Random Forest:
  n_estimators: [8,16,32,64,128,256]

Decision Tree : 
  criterion : ['squared_error', 'friedman_mse', 'absolute_error', 'poisson']                
  max_features : ['sqrt','log2']
                
Gradient Boosting:
  learning_rate : [.1,.01,.05,.001]
  subsample : [0.6,0.7,0.75,0.8,0.85,0.9]
  n_estimators : [8,16,32,64,128,256]
                
Linear Regression : {}
               
XGB Regressor:           
  learning_rate : [.1,.01,.05,.001]
  n_estimators : [8,16,32,64,128,256]

AdaBoost Regressor :           
  learning_rate : [.1,.01,0.5,.001]    
  n_estimators : [8,16,32,64,128,256]
                
Catboost Regressor:              
  depth : [6,8,10]
  learning_rate : [0.01, 0.05, 0.1]
  iterations : [30, 50, 100]

KNN Regressor :
  n_neighbors : [5,7,9,11]

                